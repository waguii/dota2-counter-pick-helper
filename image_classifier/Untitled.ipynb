{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f45f010c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 10s 1s/step - loss: 5.4526 - accuracy: 0.0100 - val_loss: 7.2053 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 4s 943ms/step - loss: 1.4285 - accuracy: 0.9700 - val_loss: 8.3332 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.2012 - accuracy: 1.0000 - val_loss: 8.9381 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 4s 924ms/step - loss: 0.0990 - accuracy: 1.0000 - val_loss: 10.1816 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0900 - accuracy: 0.9900 - val_loss: 11.9615 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 4s 954ms/step - loss: 0.1009 - accuracy: 0.9900 - val_loss: 12.7990 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 4s 929ms/step - loss: 0.0990 - accuracy: 1.0000 - val_loss: 13.2147 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.1124 - accuracy: 0.9800 - val_loss: 13.6165 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0746 - accuracy: 1.0000 - val_loss: 14.5312 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 4s 988ms/step - loss: 0.1267 - accuracy: 0.9800 - val_loss: 17.5574 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 1s 654ms/step\n",
      "As classes identificadas na imagem são: []\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Definir o diretório de imagens para treinamento\n",
    "train_dir = 'hero_pick_images'\n",
    "\n",
    "def preprocess_image(img_path):\n",
    "    img = tf.keras.preprocessing.image.load_img(img_path, target_size=(256, 144))\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    return tf.keras.applications.mobilenet_v2.preprocess_input(img_array)\n",
    "\n",
    "def train_model(image_dir):\n",
    "    images = []\n",
    "    labels = []\n",
    "    class_names = list({os.path.splitext(img_file)[0] for img_file in os.listdir(image_dir) if img_file.endswith('.png')})\n",
    "\n",
    "    for img_file in os.listdir(image_dir):\n",
    "        img_path = os.path.join(image_dir, img_file)\n",
    "        class_name = os.path.splitext(img_file)[0]\n",
    "        \n",
    "        images.append(preprocess_image(img_path))\n",
    "        labels.append(class_names.index(class_name))\n",
    "\n",
    "    images = np.vstack(images)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(256, 144, 3))\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    predictions = Dense(len(class_names), activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(images, labels, batch_size=32, epochs=10, validation_split=0.2)\n",
    "\n",
    "    return model, class_names\n",
    "\n",
    "def predict_single_image(model, img_path):\n",
    "    processed_img = preprocess_image(img_path)\n",
    "    predictions = model.predict(processed_img)\n",
    "    return predictions\n",
    "\n",
    "def predict_classes(predictions, class_names, threshold=0.1):\n",
    "    predicted_class_indices = np.where(predictions >= threshold)[1]\n",
    "    predicted_classes = [class_names[index] for index in predicted_class_indices]\n",
    "    return predicted_classes\n",
    "\n",
    "# Treinamento do modelo\n",
    "model, class_names = train_model(train_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dabafd9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 38ms/step\n",
      "As classes identificadas na imagem são: ['oracle', 'magnataur', 'medusa']\n"
     ]
    }
   ],
   "source": [
    "def predict_classes(predictions, class_names, threshold=0.1):\n",
    "    predicted_class_indices = np.where(predictions >= threshold)[1]\n",
    "    predicted_classes = [class_names[index] for index in predicted_class_indices]\n",
    "    return predicted_classes\n",
    "# Predição em uma única imagem\n",
    "predictions = predict_single_image(model, '1729987324.697981.png')\n",
    "\n",
    "# Obtendo as classes previstas\n",
    "predicted_classes = predict_classes(predictions, class_names)\n",
    "\n",
    "print(f\"As classes identificadas na imagem são: {predicted_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a380ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
